{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boolean-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "neural-attention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = YOLO(\"yolov8n.yaml\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "end = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legendary-camera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time: 0.30501627922058105'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'time: {end}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "oriented-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.56  Python-3.9.2 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\runs\\detect\\train2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\runs\\detect\\train2', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\rhayr\\Downloads\\Compressed\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\rhayr\\Downloads\\Compressed\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100\u001b[0m\n",
      "Plotting labels to C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\runs\\detect\\train2\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 6 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\runs\\detect\\train2\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.76G      1.056      1.155      1.184        198        640: 100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:23<00:00,  5.88s/it\n",
      "                   all        128        929      0.674       0.65      0.702      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.16G      1.008       1.07      1.171        205        640: 100%|██████████| 8/8 [00:03<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.20s/it\n",
      "                   all        128        929      0.754      0.646      0.713      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.17G      1.047      1.031      1.156        283        640: 100%|██████████| 8/8 [00:02<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.20s/it\n",
      "                   all        128        929       0.72      0.675       0.72      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.17G      0.987      1.054      1.143        270        640: 100%|██████████| 8/8 [00:03<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:21<00:00,  5.32s/it\n",
      "                   all        128        929      0.742      0.645      0.717      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.17G      1.101      1.099      1.159        208        640: 100%|██████████| 8/8 [00:03<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:22<00:00,  5.74s/it\n",
      "                   all        128        929      0.741      0.676      0.733      0.554\n",
      "\n",
      "5 epochs completed in 0.092 hours.\n",
      "Optimizer stripped from C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\runs\\detect\\train2\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\runs\\detect\\train2\\weights\\best.pt, 6.5MB\n",
      "\n",
      "Validating C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.56  Python-3.9.2 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:22<00:00,  5.51s/it\n",
      "                   all        128        929      0.748      0.676      0.733      0.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                person        128        254      0.847      0.709      0.802      0.585\n",
      "               bicycle        128          6       0.95      0.333      0.464       0.39\n",
      "                   car        128         46      0.685      0.261      0.407      0.226\n",
      "            motorcycle        128          5      0.829        0.8       0.92       0.71\n",
      "              airplane        128          6      0.829          1      0.948      0.832\n",
      "                   bus        128          7       0.78      0.714      0.722      0.651\n",
      "                 train        128          3      0.749          1      0.995      0.852\n",
      "                 truck        128         12      0.798        0.5      0.588      0.395\n",
      "                  boat        128          6      0.523      0.372      0.557      0.329\n",
      "         traffic light        128         14      0.823      0.214      0.223      0.143\n",
      "             stop sign        128          2      0.802          1      0.995      0.647\n",
      "                 bench        128          9      0.858      0.667      0.827      0.643\n",
      "                  bird        128         16      0.868          1      0.991      0.699\n",
      "                   cat        128          4      0.714          1      0.995      0.809\n",
      "                   dog        128          9      0.672      0.889      0.931      0.706\n",
      "                 horse        128          2      0.767          1      0.995      0.597\n",
      "              elephant        128         17      0.963      0.941      0.947      0.782\n",
      "                  bear        128          1      0.605          1      0.995      0.995\n",
      "                 zebra        128          4      0.865          1      0.995      0.975\n",
      "               giraffe        128          9      0.876          1      0.984      0.792\n",
      "              backpack        128          6      0.657      0.333      0.416      0.271\n",
      "              umbrella        128         18      0.654      0.611      0.701      0.501\n",
      "               handbag        128         19      0.791      0.201       0.35      0.147\n",
      "                   tie        128          7      0.705      0.857      0.822      0.627\n",
      "              suitcase        128          4      0.502          1      0.995      0.772\n",
      "               frisbee        128          5      0.794        0.6        0.7        0.6\n",
      "                  skis        128          1      0.706          1      0.995      0.597\n",
      "             snowboard        128          7       0.49      0.857      0.819      0.593\n",
      "           sports ball        128          6      0.784        0.5      0.636      0.373\n",
      "                  kite        128         10      0.848      0.562      0.627      0.244\n",
      "          baseball bat        128          4      0.383       0.25      0.211      0.117\n",
      "        baseball glove        128          7      0.882      0.429      0.433      0.304\n",
      "            skateboard        128          5      0.669        0.6      0.609      0.429\n",
      "         tennis racket        128          7          1      0.399      0.596      0.423\n",
      "                bottle        128         18      0.548      0.333      0.467      0.282\n",
      "            wine glass        128         16      0.605      0.863      0.808      0.444\n",
      "                   cup        128         36      0.711      0.417      0.519       0.37\n",
      "                  fork        128          6          1      0.289      0.484      0.322\n",
      "                 knife        128         16       0.71      0.625      0.673      0.408\n",
      "                 spoon        128         22      0.535      0.409      0.504      0.322\n",
      "                  bowl        128         28      0.619       0.75      0.767      0.673\n",
      "                banana        128          1          1          0      0.199     0.0329\n",
      "              sandwich        128          2          1      0.961      0.995      0.995\n",
      "                orange        128          4      0.835          1      0.995       0.73\n",
      "              broccoli        128         11      0.759      0.273      0.389      0.301\n",
      "                carrot        128         24      0.811      0.708      0.836      0.558\n",
      "               hot dog        128          2      0.538          1      0.828      0.796\n",
      "                 pizza        128          5      0.854          1      0.995      0.877\n",
      "                 donut        128         14       0.64          1      0.973      0.885\n",
      "                  cake        128          4      0.774          1      0.995      0.885\n",
      "                 chair        128         35       0.46      0.429      0.496      0.307\n",
      "                 couch        128          6      0.676      0.701      0.879      0.641\n",
      "          potted plant        128         14      0.652      0.714      0.783       0.61\n",
      "                   bed        128          3          1      0.968      0.995      0.806\n",
      "          dining table        128         13      0.713      0.575      0.627        0.5\n",
      "                toilet        128          2          1      0.889      0.995      0.946\n",
      "                    tv        128          2      0.881          1      0.995      0.895\n",
      "                laptop        128          3          1      0.878      0.995      0.842\n",
      "                 mouse        128          2          1          0      0.154     0.0842\n",
      "                remote        128          8      0.757      0.625        0.7      0.557\n",
      "            cell phone        128          8          0          0      0.106     0.0532\n",
      "             microwave        128          3      0.736          1      0.913      0.766\n",
      "                  oven        128          5      0.534        0.4      0.454      0.359\n",
      "                  sink        128          6       0.78      0.333      0.605      0.385\n",
      "          refrigerator        128          5      0.842        0.8      0.872        0.7\n",
      "                  book        128         29       0.62      0.276      0.415      0.239\n",
      "                 clock        128          9      0.924      0.889      0.918      0.802\n",
      "                  vase        128          2      0.534          1      0.828      0.745\n",
      "              scissors        128          1      0.762          1      0.995      0.221\n",
      "            teddy bear        128         21      0.851      0.545      0.779      0.545\n",
      "            toothbrush        128          5      0.788      0.753      0.928      0.579\n",
      "Speed: 0.9ms preprocess, 3.4ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\runs\\detect\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.train(data=\"coco128.yaml\", epochs=5)\n",
    "end = divmod(time.time()-start, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "needed-chemical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train time: (6.0, 1.5228426456451416)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'train time: {end}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-preservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.56  Python-3.9.2 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "Dataset 'coco.yaml' images not found , missing paths ['C:\\\\Users\\\\rhayr\\\\Downloads\\\\Compressed\\\\datasets\\\\coco\\\\val2017.txt']\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels-segments.zip to C:\\Users\\rhayr\\Downloads\\Compressed\\datasets\\coco2017labels-segments.zip...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 169M/169M [00:08<00:00, 21.9MB/s]\n",
      "Unzipping C:\\Users\\rhayr\\Downloads\\Compressed\\datasets\\coco2017labels-segments.zip to C:\\Users\\rhayr\\Downloads\\Compressed\\datasets...\n",
      "Downloading http://images.cocodataset.org/zips/train2017.zip to C:\\Users\\rhayr\\Downloads\\Compressed\\datasets\\coco\\images\\train2017.zip...\n",
      "Downloading http://images.cocodataset.org/zips/val2017.zip to C:\\Users\\rhayr\\Downloads\\Compressed\\datasets\\coco\\images\\val2017.zip...\n",
      "Downloading http://images.cocodataset.org/zips/test2017.zip to C:\\Users\\rhayr\\Downloads\\Compressed\\datasets\\coco\\images\\test2017.zip...\n",
      "Unzipping C:\\Users\\rhayr\\Downloads\\Compressed\\datasets\\coco\\images\\val2017.zip to C:\\Users\\rhayr\\Downloads\\Compressed\\datasets\\coco\\images...\n"
     ]
    }
   ],
   "source": [
    "start2 = time.time()\n",
    "metrics = model.val()\n",
    "end2 = divmod(time.time()-start, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prime-islam",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/10 C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\Images\\test\\000000000139.jpg: 448x640 1 person, 5 chairs, 1 potted plant, 2 dining tables, 1 tv, 1 refrigerator, 1 clock, 1 vase, 96.0ms\n",
      "image 2/10 C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\Images\\test\\000000000285.jpg: 640x608 1 bear, 96.0ms\n",
      "image 3/10 C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\Images\\test\\000000000632.jpg: 512x640 1 bottle, 1 chair, 2 potted plants, 1 bed, 2 books, 91.0ms\n",
      "image 4/10 C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\Images\\test\\000000000724.jpg: 640x480 1 truck, 2 stop signs, 98.0ms\n",
      "image 5/10 C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\Images\\test\\000000000776.jpg: 640x448 4 teddy bears, 94.0ms\n",
      "image 6/10 C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\Images\\test\\000000000785.jpg: 448x640 1 person, 1 skis, 7.0ms\n",
      "image 7/10 C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\Images\\test\\000000000802.jpg: 640x448 1 oven, 1 refrigerator, 8.0ms\n",
      "image 8/10 C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\Images\\test\\000000000872.jpg: 640x640 2 persons, 1 sports ball, 8.0ms\n",
      "image 9/10 C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\Images\\test\\000000000885.jpg: 448x640 4 persons, 1 tennis racket, 9.0ms\n",
      "image 10/10 C:\\Users\\rhayr\\Downloads\\Compressed\\ultralytics\\Images\\test\\000000001000.jpg: 480x640 13 persons, 2 tennis rackets, 88.0ms\n",
      "Speed: 1.0ms preprocess, 59.5ms inference, 46.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 6.878409147262573)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results = model.predict('C:\\\\Users\\\\rhayr\\\\Downloads\\\\Compressed\\\\ultralytics\\\\Images\\\\test')\n",
    "end = divmod(time.time()-start, 60)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-conducting",
   "metadata": {},
   "source": [
    "Speed: 0.2ms preprocess, 58.9ms inference, 46.2ms postprocess per image at shape (1, 3, 640, 640)\n",
    "Speed: 0.5ms preprocess, 60.9ms inference, 46.8ms postprocess per image at shape (1, 3, 640, 640)\n",
    "Speed: 0.4ms preprocess, 60.8ms inference, 46.9ms postprocess per image at shape (1, 3, 640, 640)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
